<div>
<p>
I recently wrote a <a href="https://jarombek.com/blog/apr-1-2019-docker-pt1">series</a>
<a href="https://jarombek.com/blog/apr-8-2019-docker-pt2">of</a> <a href="https://jarombek.com/blog/
apr-28-2019-docker-pt3">articles</a> on Docker and containerized applications.  In those articles
I worked with a single Docker container at a time.  Each container was mapped to a post on the host
machines IP, making it accessible from the browser.  In my case, the host machine was an EC2 instance.
</p>
<p>
While the single container approach works, it has a number of limitations and drawbacks.  First off,
a single container isn’t scalable.  As web traffic to an application increases, the load becomes too
much for a single container to handle.  There is also no zero-downtime approach to release a new
version of an application.  The container running the old version has to stop and a container with
the new version has to start in its place.  While both these limitations are deal breakers in
themselves, the worst part about the single container approach is that its a single point of failure.
If the container stops or the application running on it crashes, the entire application goes down.
This makes deploying a production application on a single container inadequate.
</p>
<p>
The tool to solve these issues is a container orchestrator.  The most popular container orchestrator
right now is Kubernetes.
</p>
<Definition word="Container Orchestrator">
A container orchestrator is a tool that manages the lifecycle of containers.  Orchestrators handle
container scaling, self-healing, load balancing, deployment, and more<sup>1</sup>.  Orchestrators
are portable from bare-metal machines to the cloud, effectively abstracting away the underlying
infrastructure<sup>2</sup>.  This allows DevOps engineers to focus on the most important aspect
of a project - the application itself.
</Definition>
<p>
The second most popular container orchestrator is Docker Swarm, which I will likely explore in a future
post.  The rest of this post explains the basic concepts on Kubernetes and deploys an application on
a single node Kubernetes cluster.
</p>
<SectionTitle title="Kubernetes Concepts">Kubernetes Concepts</SectionTitle>
<p>
As previously mentioned, Kubernetes is a container orchestrator.  To work with Kubernetes, a cluster
is created consisting of a master node and worker nodes.  A node can be a bare-metal server or virtual
machine.  Nodes are often virtual machines hosted in the cloud, such as an Amazon EC2 VM.
</p>
<p>
There are two types of nodes - masters and workers.  Master nodes run the Kubernetes Control Plane,
which you can think of as the brain of the cluster.  Worker nodes run application pods and services.
Let’s explore the master node first.
</p>
<SectionTitle title="Master Node">Master Node</SectionTitle>
<p>
As previously mentioned, master nodes run the Kubernetes Control Plane.  There are four main pieces
of the Control Plane - persistent storage, Kubernetes API, Scheduler, and Controller Manager<sup>3</sup>.
</p>
<p>
The Kubernetes <strong>API server</strong> is a CRUD API that describes and modifies objects in the
cluster<sup>4,5</sup>.  Interaction with the Kubernetes API server is often done through a CLI called
<code class="jarombek-inline-code">kubectl</code>.  However, since the API server is a REST API, you
can also interact with it using HTTP requests.
</p>
<p>
Objects in a Kubernetes cluster are represented as YAML documents.  YAML is a superset of JSON, so
you can write documents with JSON as well.  Objects represent the desired state of the Kubernetes
cluster.  An example of an object is a pod, which contains one or more containers.  Another example
is a replica set, which self-heals and horizontally scales a pod (allows you to have many pods with
the same configuration).  The YAML file declares the desired state of the pod or replica set in the cluster.
</p>
<p>
The most common approach for adding an object to a Kubernetes cluster is to send a YAML file to the
API server.  This is usually done through the <code class="jarombek-inline-code">kubectl</code> CLI
with the <code class="jarombek-inline-code">kubectl create file.yml</code> or
<code class="jarombek-inline-code">kubectl apply file.yml</code> commands.  For example, the following
YAML file creates a pod object which holds a single container.
</p>
<CodeSnippet language="YAML">
# pod.yml

# Version of the Kubernetes API.  Pods exist in the stable v1 version
apiVersion: v1
# What kind of object to deploy (in this case a Pod)
kind: Pod
# Metadata describing the Pod object
metadata:
  name: nodejs-app
  labels:
    app: nodejs-app
    version: v1.0.0
    environment: sandbox
spec:
  containers:
    # Unique name for the container in the pod
  - name: nodejs-app
    # Docker image to use for the container from DockerHub
    image: ajarombek/nodejs-docker-app:latest
    # Configure a network port for a container
    ports:
      # Port to expose on the container IP
    - containerPort: 3000
      # Protocol defaults to TCP
      protocol: TCP
</CodeSnippet>
<p>
The Pod contains a container running a simple Node.js/Express web application.  To deploy this object
on a Kubernetes cluster, the following <code class="jarombek-inline-code">kubectl</code> command is run:
</p>
<CodeSnippet language="Bash">
kubectl create -f pod.yml
</CodeSnippet>
<p>
<code class="jarombek-inline-code">kubectl</code> sends the YAML document to the API server.  When
the API server receives a YAML document, it stores all the Kubernetes objects it declares in persistent
storage as JSON<sup>6</sup>.  Kubernetes uses an etcd key-value store for <strong>persistent storage</strong>.
</p>
<p>
The last two pieces of the master node are the Scheduler and Controller Manager.  The <strong>Scheduler</strong>
runs an algorithm to determine which cluster node a pod should run on<sup>7</sup>.  The
<strong>Controller Manager</strong> maintains multiple different controllers.  Controllers watch the
API Server for changes to Kubernetes objects<sup>8</sup>.  Most Kubernetes objects have their own
Controller.  For example, there is a ReplicaSet controller which watches for changes to
<code class="jarombek-inline-code">ReplicaSet</code> objects.  When changes occur, controllers perform
operations on the cluster.  Their objective is to keep the cluster matching the desired state declared
in the Kubernetes objects.  The only Kubernetes object that Controller’s don’t handle are Pods, which are
configured by a component called the Kubelet.  I will provide details about the Kubelet when discussing
worker nodes.
</p>
<p>
Here is a diagram of the master node and its four main components:
</p>
<figure>
<img class="jarombek-blog-image" src="https://asset.jarombek.com/posts/5-13-19-k8s-master.png"/>
</figure>
<ComparisonTable title="Master Node Components">
<ComparisonTableEntry>
<h5 className="jarombek-cte-title">API Server</h5>
<div className="jarombek-cte-body">
<p>
The central component of the master node.  It is a REST API which stores JSON documents in persistent
storage.  JSON documents are Kubernetes objects which represent the desired state of the cluster.
</p>
</div>
</ComparisonTableEntry>
<ComparisonTableEntry>
<h5 className="jarombek-cte-title">Persistent Storage</h5>
<div className="jarombek-cte-body">
<p>
An etcd key-value store which holds JSON documents.  The structure of etcd is compared to a filesystem
containing JSON files.  Each JSON file represents a Kubernetes object.  The etcd database is highly
available, making it resistant to failures.
</p>
</div>
</ComparisonTableEntry>
<ComparisonTableEntry>
<h5 className="jarombek-cte-title">Scheduler</h5>
<div className="jarombek-cte-body">
<p>
Waits for new pod definitions on the API server and schedules them to worker nodes.  The scheduler runs
an algorithm to determine which node is the best fit for a pod.
</p>
</div>
</ComparisonTableEntry>
<ComparisonTableEntry>
<h5 className="jarombek-cte-title">Controller Manager</h5>
<div className="jarombek-cte-body">
<p>
While the API Server is the central component of the master node, it doesn’t do anything besides accept
API requests and write JSON to etcd.  The controller manager performs the actual work in the cluster
based on the desired state exposed by the API Server.  This work keeps the cluster in its desired state.
</p>
</div>
</ComparisonTableEntry>
</ComparisonTable>
<SectionTitle title="Worker Nodes">Worker Nodes</SectionTitle>
<p>
Worker nodes run applications and services.  Worker nodes are equipped with a Kubelet, kube-proxy, and
container runtime.
</p>
<p>
The <strong>Kubelet</strong> has two main jobs.  The first is to register the machine its running on
as a worker node for the cluster.  The second is to watch the API Server for Pods that are scheduled
to run on the worker node it initialized<sup>9</sup>.  The role of starting the Pods is left to the
Container Runtime.  Kubernetes can be configured with many different Container Runtimes, the most
common of which is Docker.
</p>
<p>
The last major piece of the worker node is the <strong>kube-proxy</strong>.   While not actually a proxy
server as the name suggests, kube-proxy makes sure that Pods are reachable via a static IP address<sup>10</sup>.
This static IP address is created by a Kubernetes object known as a Service.  I will discuss services
in more detail in my next Kubernetes article.
</p>
<p>
Here is a diagram of the worker node and its four main components:
</p>
<figure>
<img class="jarombek-blog-image" src="https://asset.jarombek.com/posts/5-13-19-k8s-worker.png"/>
</figure>
<ComparisonTable title="Worker Node Components">
<ComparisonTableEntry>
<h5 className="jarombek-cte-title">Kubelet</h5>
<div className="jarombek-cte-body">
<p>
A component that watches the API Server for Pod objects scheduled to run on its node.  The Kubelet
notifies the Container Runtime to start Pods after they are scheduled.  It also destroys Pods after
they are removed from the API Server and tells the Container Runtime to restart a container when
they fail health checks.
</p>
</div>
</ComparisonTableEntry>
<ComparisonTableEntry>
<h5 className="jarombek-cte-title">kube-proxy</h5>
<div className="jarombek-cte-body">
<p>
Ensures that HTTP requests to a Service object are sent to the proper Pod.  These requests can come
from the internet or locally within the worker node.
</p>
</div>
</ComparisonTableEntry>
<ComparisonTableEntry>
<h5 className="jarombek-cte-title">Container Runtime</h5>
<div className="jarombek-cte-body">
<p>
A container runtime executes a container based off an image.  The most common Container runtime is
containerd, which is part of Docker.  The Docker container system consists of multiple decoupled
components, one of which is the container runtime (containerd)<sup>11</sup>.  Other container runtimes
can be used in the place of Docker.
</p>
</div>
</ComparisonTableEntry>
</ComparisonTable>
<p>
Here is a diagram of a three node cluster with one master node and two worker nodes:
</p>
<figure>
<img class="jarombek-blog-image" src="https://asset.jarombek.com/posts/5-13-19-k8s-cluster.png"/>
</figure>
<SectionTitle title="Conclusions">Conclusions</SectionTitle>
<p>
This article provides us with a high level view of a Kubernetes cluster.  In my next Kubernetes article,
I’ll walk through creating a simple one node cluster on AWS.  I’ll also discuss all the basic Kubernetes
objects used in an application.  I’m also building a full Kubernetes prototype application, which is
available on <a href="https://github.com/AJarombek/kubernetes-prototype">GitHub</a>!
</p>
</div>