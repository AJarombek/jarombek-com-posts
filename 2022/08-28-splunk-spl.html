<div>
<p>
Recently at work, I’ve used Splunk Enterprise extensively to analyze application logs.  In Splunk, I’m able to query
logs, set alerts when certain scenarios occur within logs, and create dashboards to visualize logs for fellow engineers
and business analysts.  Splunk provides its own query language to interact with logs on its platform; Splunk Processing
Language (SPL) is used for searching, alerting, and dashboard creation<sup>1</sup>.
</p>
<p>
Although Splunk querying has been part of my work-life for years, I never explored it on my own or used it in any
personal projects.  Recently I decided to run a local Splunk Enterprise server to test out its most basic properties.
This groundwork may one day lead to me adopting Splunk for monitoring my applications logs.  In this article, I
describe the basics of Splunk and how to set up a local instance on Docker.  I also discuss basic SPL commands and
queries, and how some can be run before you upload any logs of your own.
</p>
<SectionTitle title="Splunk Overview">Splunk Overview</SectionTitle>
<Definition word="Splunk Enterprise">
Splunk Enterprise is software enabling log analysis on application, infrastructure, and security logs.  Splunk
consists of a web interface, query language (SPL), and command line interface<sup>2</sup>.  Users forward logs from
different sources into Splunk, where it is then indexed and made available to query.  Building upon SPL queries:
alerts, dashboards, and reports can be created.  With these tools, Splunk allows individuals and organizations to view
and react to the status of logs in real-time or near real-time<sup>3</sup>.
</Definition>
<Definition word="Centralized Log Analysis Tools">
A centralized log analysis tool, like Splunk, brings together logs from across an organization or department into a
single, searchable platform.  Centralized logging brings many quality-of-life improvements to engineers; it is
considerably easier to search on Splunk for logs across many applications with a common query language instead of
accessing individual servers where logs are initially generated.
</Definition>
<p>
Splunk is often compared to another log analysis platform called Elasticsearch, which is part of the ELK stack.  I have
written about the <a href="https://jarombek.com/blog?query=elasticsearch&page=1">ELK Stack</a> in prior articles, mostly
because it was used at my prior company.  The biggest difference between the two is Splunk requires a license while the
ELK Stack is open source.  Beyond that, I view the choice between the two platforms as a
<a href="https://www.gartner.com/reviews/market/security-information-event-management/compare/elasticsearch-vs-splunk">
personal preference</a><sup>4</sup>.
</p>
<SectionTitle title="Running Splunk Locally on Docker">Running Splunk Locally on Docker</SectionTitle>
<p>
Splunk Enterprise provides <a href="https://hub.docker.com/r/splunk/splunk/tags">official Docker images</a> on
DockerHub.  If Docker is installed and running on your computer, starting a Splunk server is as simple as the following
two shell commands.
</p>
<CodeSnippet language="Bash">
docker pull splunk/splunk:latest
docker run -d \
    -p 8000:8000 \
    -e "SPLUNK_START_ARGS=--accept-license" \
    -e "SPLUNK_PASSWORD=splunkadmin" \
    --name splunk \
    splunk/splunk:latest
</CodeSnippet>
<p>
It may take a minute for the container to be ready.  With the Docker container running, navigating to
<strong>localhost:8080</strong> in a web browser should show the following sign-in screen.
</p>
<InlineImage filename="8-28-22-splunk-sign-in.png" paddingTop="true" paddingBottom="true">
</InlineImage>
<p>
Sign in with the credentials configured in the shell command: <strong>admin</strong> for the username and
<strong>splunkadmin</strong> for the password.  After signing in, you are presented with the homepage for Splunk
Enterprise!
</p>
<InlineImage filename="8-28-22-splunk-homepage.png" paddingTop="true" paddingBottom="true">
</InlineImage>
<p>
Now we are ready to start using Splunk.  Before forwarding any logs to Splunk, we can utilize Splunk’s default indexes
to practice writing simple queries.  An index in Splunk is a repository of data (logs), and the act of indexing
transforms raw data sitting in files at an index into searchable events<sup>5,6</sup>.  One of these indexes present
on every Splunk installation by default is <code className="jarombek-inline-code">_internal</code>.  From the Splunk
homepage, clicking on "Search & Reporting" on the left-hand sidebar presents the search screen.  From here, entering
the following query will retrieve events from the <code className="jarombek-inline-code">_internal</code> index.
</p>
<CodeSnippet language="SPL">
index=_internal
</CodeSnippet>
<InlineImage filename="8-28-22-splunk-query.png" paddingTop="true" paddingBottom="true">
</InlineImage>
<p>
On the left-hand side of the screen, a list of fields are shown which exist in events and are queryable on the current
index.  A slightly more complex query might perform statistical analysis on one of these fields.  The following query
aggregates the events and checks the count of each unique value in the
<code className="jarombek-inline-code">source</code> field.
</p>
<CodeSnippet language="SPL">
index=_internal
| stats count by source
</CodeSnippet>
<InlineImage filename="8-28-22-splunk-count-query.png" paddingTop="true" paddingBottom="true">
</InlineImage>
<SectionTitle title="Basic SPL Queries and Commands">Basic SPL Queries and Commands</SectionTitle>
<SectionTitle title="Querying Application Logs">Querying Application Logs</SectionTitle>
<SectionTitle title="Conclusions">Conclusions</SectionTitle>
</div>